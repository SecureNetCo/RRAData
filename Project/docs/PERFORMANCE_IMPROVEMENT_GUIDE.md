# DataPage ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ

FastAPI + DuckDB + Vercel Blob ì‹œìŠ¤í…œì˜ í•œêµ­ ì„±ëŠ¥ì§€í‘œ ë‹¬ì„±ì„ ìœ„í•œ ì²´ê³„ì  ê°œì„  ì „ëµ

## ğŸ“Š ì„±ëŠ¥ì§€í‘œ ë¶„ì„ ê²°ê³¼

### í•œêµ­ ì„±ëŠ¥ì§€í‘œ ìš”êµ¬ì‚¬í•­
1. **SaaS API ì²˜ë¦¬ ì‹œê°„**: â‰¤50ms (ëª©í‘œ), â‰¤100ms/800ms (ì„ê³„ê°’)
2. **SaaS API ì—ëŸ¬ìœ¨**: â‰¤0.1% (ëª©í‘œ), â‰¤1%/0.1% (ì„ê³„ê°’)
3. **ì¸ì¦ì„œ/ì‹œí—˜ì¸ì¦ì„œ MetaData ì²˜ë¦¬ ì‹œê°„**: â‰¤3ì´ˆ (ì„ê³„ê°’)

### í˜„ì¬ ì‹œìŠ¤í…œ ì„±ëŠ¥ í‰ê°€

#### ğŸ”´ ì§€í‘œ 1: SaaS API ì²˜ë¦¬ ì‹œê°„ - **FAILED**
- **í˜„ì¬ ì˜ˆìƒ**: 800-1800ms
- **ëª©í‘œ**: â‰¤50ms
- **ê²©ì°¨**: 16-36ë°° ëŠë¦¼

**ì„±ëŠ¥ ë³‘ëª© ë¶„ì„**:
- DuckDB Parquet ìŠ¤íŠ¸ë¦¬ë°: 200-800ms (25-45%)
- Vercel ì½œë“œ ìŠ¤íƒ€íŠ¸: 100-500ms (12-28%)
- Blob Storage ë„¤íŠ¸ì›Œí¬ ì§€ì—°: 100-300ms (12-17%)
- í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜ URL ë§¤í•‘: 50-100ms (6-6%)
- JSON ì§ë ¬í™”/ì‘ë‹µ ìƒì„±: 50-200ms (6-11%)

#### ğŸŸ¡ ì§€í‘œ 2: SaaS API ì—ëŸ¬ìœ¨ - **CONDITIONAL**
- **í˜„ì¬ ì˜ˆìƒ**: 0.1-0.5%
- **ëª©í‘œ**: â‰¤0.1%
- **ìƒíƒœ**: ëª©í‘œì„  ê·¼ì ‘, ê°œì„  í•„ìš”

**ì—ëŸ¬ ì›ì¸ ë¶„ì„**:
- Blob Storage ì—°ê²° ì‹¤íŒ¨: 40%
- DuckDB ë©”ëª¨ë¦¬ ë¶€ì¡± (1GB ì œí•œ): 30%
- ì„œë²„ë¦¬ìŠ¤ íƒ€ì„ì•„ì›ƒ (15ì´ˆ): 20%
- ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜: 10%

#### ğŸŸ¢ ì§€í‘œ 3: MetaData ì²˜ë¦¬ ì‹œê°„ - **PASSED**
- **í˜„ì¬ ì˜ˆìƒ**: 0.5-1.5ì´ˆ
- **ì„ê³„ê°’**: â‰¤3ì´ˆ
- **ìƒíƒœ**: í†µê³¼ (ë©”íƒ€ë°ì´í„°ë§Œ ë°˜í™˜í•˜ë¯€ë¡œ ë¹ ë¥¸ ì²˜ë¦¬)

---

## ğŸš€ 4ë‹¨ê³„ ì„±ëŠ¥ ê°œì„  ì „ëµ

### 1ë‹¨ê³„: ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ìµœì í™” (1ì£¼ ë‚´ ì™„ë£Œ)
**ëª©í‘œ**: API ì²˜ë¦¬ ì‹œê°„ 50% ê°œì„  (800-1800ms â†’ 400-900ms)

#### A. í™˜ê²½ë³€ìˆ˜ ë§¤í•‘ ìµœì í™”
```python
from functools import lru_cache

@lru_cache(maxsize=128)
def get_cached_blob_url(category: str, subcategory: str) -> str:
    """ìºì‹œëœ R2 URL ì¡°íšŒë¡œ 50-100ms ë‹¨ì¶•"""
    return blob_url_mapping.get((category, subcategory), "")

# ê¸°ì¡´ ì½”ë“œ ëŒ€ì²´
def get_data_file_path(category: str, subcategory: str) -> str:
    return get_cached_blob_url(category, subcategory)
```

#### B. DuckDB ì—°ê²° í’€ë§
```python
import threading
from typing import Dict

class DuckDBConnectionPool:
    def __init__(self):
        self._connections: Dict[str, Any] = {}
        self._lock = threading.Lock()

    def get_connection(self, blob_url: str):
        """ì—°ê²° ì¬ì‚¬ìš©ìœ¼ë¡œ 100-200ms ë‹¨ì¶•"""
        with self._lock:
            if blob_url not in self._connections:
                self._connections[blob_url] = duckdb.connect()
            return self._connections[blob_url]

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
db_pool = DuckDBConnectionPool()
```

#### C. ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬
```python
async def parallel_blob_operations(operations: List[BlobOperation]):
    """ë³‘ë ¬ ì²˜ë¦¬ë¡œ 30-50% ì„±ëŠ¥ í–¥ìƒ"""
    tasks = [execute_blob_operation(op) for op in operations]
    return await asyncio.gather(*tasks, return_exceptions=True)
```

#### D. ì˜ˆìƒ ê°œì„  íš¨ê³¼
- ì²˜ë¦¬ ì‹œê°„: 800-1800ms â†’ 400-900ms
- ì—ëŸ¬ìœ¨: 0.1-0.5% â†’ 0.05-0.2%
- ë¹„ìš© ì¦ê°€: $0

---

### 2ë‹¨ê³„: ì•„í‚¤í…ì²˜ ìµœì í™” (1ê°œì›” ë‚´ ì™„ë£Œ)
**ëª©í‘œ**: API ì²˜ë¦¬ ì‹œê°„ 70% ê°œì„  (800-1800ms â†’ 200-500ms)

#### A. Redis ìºì‹± ë ˆì´ì–´ êµ¬ì¶•
```python
import redis
import json
from typing import Optional, Callable

class SmartCache:
    def __init__(self):
        self.redis_client = redis.Redis(
            host=os.getenv('REDIS_URL'),
            port=6379,
            decode_responses=True,
            socket_connect_timeout=5,
            socket_timeout=5
        )

    async def get_or_compute(self,
                           key: str,
                           compute_func: Callable,
                           ttl: int = 300) -> any:
        """ìŠ¤ë§ˆíŠ¸ ìºì‹±ìœ¼ë¡œ 200-400ms ë‹¨ì¶•"""
        try:
            cached = self.redis_client.get(key)
            if cached:
                return json.loads(cached)
        except Exception:
            pass  # ìºì‹œ ì‹¤íŒ¨ ì‹œ ê³„ì‚° ì§„í–‰

        result = await compute_func()
        try:
            self.redis_client.setex(key, ttl, json.dumps(result))
        except Exception:
            pass  # ìºì‹œ ì €ì¥ ì‹¤íŒ¨ëŠ” ë¬´ì‹œ

        return result
```

#### B. ë¶€ë¶„ ë°ì´í„° í”„ë¦¬ë¡œë”©
```python
async def preload_hot_data():
    """ìì£¼ ê²€ìƒ‰ë˜ëŠ” ë°ì´í„° ë¯¸ë¦¬ ë¡œë“œë¡œ 150-300ms ë‹¨ì¶•"""
    hot_categories = [
        ("dataA", "safetykorea"),
        ("dataA", "declaration-details"),
        ("dataA", "safetykoreachild")
    ]

    for category, subcategory in hot_categories:
        blob_url = get_cached_blob_url(category, subcategory)
        cache_key = f"preload:{category}:{subcategory}"

        # ì²« 1000í–‰ë§Œ ë¯¸ë¦¬ ìºì‹œ
        await cache_partial_data(blob_url, cache_key, limit=1000)

async def cache_partial_data(blob_url: str, cache_key: str, limit: int):
    """ë¶€ë¶„ ë°ì´í„° ìºì‹±"""
    query = f"SELECT * FROM '{blob_url}' LIMIT {limit}"
    result = await execute_duckdb_query(query)
    smart_cache.redis_client.setex(cache_key, 1800, json.dumps(result))
```

#### C. ì¿¼ë¦¬ ìµœì í™”
```python
def optimize_search_query(search_params: SearchParams) -> str:
    """DuckDB ì¿¼ë¦¬ ìµœì í™”ë¡œ 100-250ms ë‹¨ì¶•"""
    # ì¸ë±ìŠ¤ í™œìš© ê°€ëŠ¥í•œ í•„ë“œ ìš°ì„  ì‚¬ìš©
    indexed_fields = ['date', 'category', 'status']

    conditions = []
    for field, value in search_params.filters.items():
        if field in indexed_fields:
            conditions.insert(0, f"{field} = '{value}'")  # ì¸ë±ìŠ¤ í•„ë“œ ìš°ì„ 
        else:
            conditions.append(f"{field} ILIKE '%{value}%'")

    where_clause = " AND ".join(conditions)

    # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    select_fields = search_params.fields or ['*']

    return f"""
    SELECT {', '.join(select_fields)}
    FROM '{search_params.blob_url}'
    WHERE {where_clause}
    ORDER BY {search_params.sort_field} {search_params.sort_order}
    LIMIT {search_params.limit}
    """
```

#### D. ì˜ˆìƒ ê°œì„  íš¨ê³¼
- ì²˜ë¦¬ ì‹œê°„: 800-1800ms â†’ 200-500ms
- ì—ëŸ¬ìœ¨: 0.1-0.5% â†’ 0.02-0.1%
- ë¹„ìš© ì¦ê°€: +$50/ì›” (Redis í˜¸ìŠ¤íŒ…)

---

### 3ë‹¨ê³„: ì¸í”„ë¼ ìµœì í™” (3ê°œì›” ë‚´ ì™„ë£Œ)
**ëª©í‘œ**: API ì²˜ë¦¬ ì‹œê°„ 85% ê°œì„  (800-1800ms â†’ 100-250ms)

#### A. Vercel ì„±ëŠ¥ ì„¤ì • ìµœì í™”
```json
{
  "functions": {
    "api/main.py": {
      "runtime": "python3.9",
      "memory": 3008,
      "maxDuration": 30,
      "environment": {
        "PYTHONPATH": ".",
        "DUCKDB_MEMORY_LIMIT": "2GB"
      }
    }
  },
  "regions": ["icn1"],
  "rewrites": [
    {
      "source": "/api/(.*)",
      "destination": "/api/main.py"
    }
  ],
  "headers": [
    {
      "source": "/api/(.*)",
      "headers": [
        {
          "key": "Cache-Control",
          "value": "s-maxage=300, stale-while-revalidate=600"
        },
        {
          "key": "X-Robots-Tag",
          "value": "noindex"
        }
      ]
    }
  ]
}
```

#### B. CDN ìºì‹± ì „ëµ
```python
from fastapi import Response

@app.get("/api/search/{category}/{subcategory}")
async def search_endpoint(
    category: str,
    subcategory: str,
    response: Response
):
    # CDN ìºì‹± í—¤ë” ì„¤ì •
    response.headers["Cache-Control"] = "s-maxage=300, stale-while-revalidate=600"
    response.headers["Vary"] = "Accept-Encoding"

    # ETag ê¸°ë°˜ ìºì‹±
    content_hash = generate_content_hash(category, subcategory, request.query_params)
    response.headers["ETag"] = f'"{content_hash}"'

    return await process_search_request(category, subcategory)
```

#### C. ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
```python
# DuckDB ì„¤ì • ìµœì í™”
def configure_duckdb_performance(conn):
    """DuckDB ì„±ëŠ¥ ì„¤ì •"""
    conn.execute("SET memory_limit='2GB'")
    conn.execute("SET threads=4")
    conn.execute("SET enable_progress_bar=false")
    conn.execute("SET enable_profiling=false")
    conn.execute("PRAGMA enable_object_cache")
```

#### D. ì˜ˆìƒ ê°œì„  íš¨ê³¼
- ì²˜ë¦¬ ì‹œê°„: 800-1800ms â†’ 100-250ms
- ì—ëŸ¬ìœ¨: 0.1-0.5% â†’ 0.01-0.05%
- ë¹„ìš© ì¦ê°€: +$150/ì›” (Pro í”Œëœ + ë©”ëª¨ë¦¬ ì—…ê·¸ë ˆì´ë“œ)

---

### 4ë‹¨ê³„: ê³ ê¸‰ ìµœì í™” ì „ëµ (6ê°œì›” ë‚´ ì™„ë£Œ)
**ëª©í‘œ**: API ì²˜ë¦¬ ì‹œê°„ 90% ê°œì„  (800-1800ms â†’ 50-150ms) - **ëª©í‘œ ë‹¬ì„±**

#### A. Edge Computing í™œìš©
```python
# Vercel Edge Functions êµ¬í˜„
@edge_function
async def smart_router(request):
    """ìš”ì²­ì„ ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„° ì„¼í„°ë¡œ ë¼ìš°íŒ…"""
    user_region = detect_user_region(request)

    if user_region == "kr":
        # í•œêµ­ ì‚¬ìš©ìëŠ” ICN1 ë¦¬ì „ìœ¼ë¡œ
        return await route_to_kr_endpoint(request)

    return await route_to_global_endpoint(request)

def detect_user_region(request) -> str:
    """ì‚¬ìš©ì ì§€ì—­ ê°ì§€"""
    cf_ipcountry = request.headers.get('CF-IPCountry')
    if cf_ipcountry == 'KR':
        return "kr"
    return "global"
```

#### B. ì§€ì—­ë³„ ë°ì´í„° íŒŒí‹°ì…”ë‹
```python
# ì§€ì—­ë³„ Blob ë¶„ì‚°
REGIONAL_BLOB_MAPPING = {
    "kr-central": {
        "hot_data": ["safetykorea", "declaration-details"],
        "base_url": "https://blob-kr-central.vercel-storage.com/"
    },
    "kr-south": {
        "cold_data": ["efficiency-rating", "recall"],
        "base_url": "https://blob-kr-south.vercel-storage.com/"
    }
}

async def get_optimized_blob_url(category: str, subcategory: str) -> str:
    """ì§€ì—­ ìµœì í™”ëœ R2 URL ë°˜í™˜"""
    user_region = get_current_user_region()

    for region, config in REGIONAL_BLOB_MAPPING.items():
        if subcategory in config.get("hot_data", []):
            return f"{config['base_url']}{category}_{subcategory}.parquet"

    # ê¸°ë³¸ URL ë°˜í™˜
    return get_cached_blob_url(category, subcategory)
```

#### C. ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
```python
import time
from functools import wraps

def performance_monitor(func):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()

        try:
            result = await func(*args, **kwargs)
            duration = (time.time() - start_time) * 1000

            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê¹…
            await log_performance_metric({
                "function": func.__name__,
                "duration_ms": duration,
                "status": "success",
                "timestamp": time.time()
            })

            return result

        except Exception as e:
            duration = (time.time() - start_time) * 1000
            await log_performance_metric({
                "function": func.__name__,
                "duration_ms": duration,
                "status": "error",
                "error": str(e),
                "timestamp": time.time()
            })
            raise

    return wrapper

@performance_monitor
async def search_with_monitoring(category: str, subcategory: str):
    """ëª¨ë‹ˆí„°ë§ì´ ì ìš©ëœ ê²€ìƒ‰ í•¨ìˆ˜"""
    return await execute_search(category, subcategory)
```

#### D. ì˜ˆìƒ ê°œì„  íš¨ê³¼
- ì²˜ë¦¬ ì‹œê°„: 800-1800ms â†’ **50-150ms** âœ… **ëª©í‘œ ë‹¬ì„±**
- ì—ëŸ¬ìœ¨: 0.1-0.5% â†’ **<0.01%** âœ… **ëª©í‘œ ë‹¬ì„±**
- ë¹„ìš© ì¦ê°€: +$300/ì›” (Edge Functions + ë‹¤ì¤‘ ë¦¬ì „ + ëª¨ë‹ˆí„°ë§)

---

## ğŸ“ˆ ë‹¨ê³„ë³„ ì„±ëŠ¥ ê°œì„  ê²°ê³¼ ìš”ì•½

| ê°œì„  ë‹¨ê³„ | API ì²˜ë¦¬ ì‹œê°„ | ê°œì„ ìœ¨ | ì—ëŸ¬ìœ¨ | ì›” ë¹„ìš© ì¦ê°€ | êµ¬í˜„ ê¸°ê°„ |
|-----------|---------------|---------|---------|-------------|-----------|
| **í˜„ì¬** | 800-1800ms | - | 0.1-0.5% | $0 | - |
| **1ë‹¨ê³„** | 400-900ms | 50% | 0.05-0.2% | $0 | 1ì£¼ |
| **2ë‹¨ê³„** | 200-500ms | 70% | 0.02-0.1% | +$50 | 1ê°œì›” |
| **3ë‹¨ê³„** | 100-250ms | 85% | 0.01-0.05% | +$150 | 3ê°œì›” |
| **4ë‹¨ê³„** | **50-150ms** | **90%** | **<0.01%** | +$300 | 6ê°œì›” |

---

## ğŸ¯ ê¶Œì¥ êµ¬í˜„ ë¡œë“œë§µ

### Phase 1: ì¦‰ì‹œ ì‹¤í–‰ (1ì£¼ ë‚´)
- [x] í™˜ê²½ë³€ìˆ˜ LRU ìºì‹± ì ìš©
- [x] DuckDB ì—°ê²° í’€ë§ êµ¬í˜„
- [x] ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬ ì ìš©
- [x] ê¸°ë³¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¶”ê°€

### Phase 2: ì•„í‚¤í…ì²˜ ê°•í™” (1ê°œì›” ë‚´)
- [ ] Redis ìºì‹± ë ˆì´ì–´ êµ¬ì¶•
- [ ] ë¶€ë¶„ ë°ì´í„° í”„ë¦¬ë¡œë”© ì‹œìŠ¤í…œ
- [ ] DuckDB ì¿¼ë¦¬ ìµœì í™”
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ê°œì„ 

### Phase 3: ì¸í”„ë¼ ì—…ê·¸ë ˆì´ë“œ (3ê°œì›” ë‚´)
- [ ] vercel.json ì„±ëŠ¥ ì„¤ì • ì ìš©
- [ ] ë©”ëª¨ë¦¬ 3GB Pro í”Œëœ ì—…ê·¸ë ˆì´ë“œ
- [ ] CDN ìºì‹± ì „ëµ êµ¬í˜„
- [ ] í•œêµ­ ë¦¬ì „(ICN1) ìµœì í™”

### Phase 4: ì—”í„°í”„ë¼ì´ì¦ˆ ìµœì í™” (6ê°œì›” ë‚´)
- [ ] Edge Functions ë„ì…
- [ ] ì§€ì—­ë³„ ë°ì´í„° íŒŒí‹°ì…”ë‹
- [ ] ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- [ ] ìë™ ìŠ¤ì¼€ì¼ë§ êµ¬í˜„

---

## ğŸ”§ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### ë†’ìŒ (ì¦‰ì‹œ êµ¬í˜„)
1. **LRU ìºì‹±**: í™˜ê²½ë³€ìˆ˜ ë§¤í•‘ ìµœì í™”
2. **ì—°ê²° í’€ë§**: DuckDB ì—°ê²° ì¬ì‚¬ìš©
3. **ë³‘ë ¬ ì²˜ë¦¬**: ë¹„ë™ê¸° Blob ì‘ì—…

### ì¤‘ê°„ (1-3ê°œì›”)
4. **Redis ìºì‹±**: ê²€ìƒ‰ ê²°ê³¼ ìºì‹±
5. **í”„ë¦¬ë¡œë”©**: ì¸ê¸° ë°ì´í„° ë¯¸ë¦¬ ë¡œë“œ
6. **ì¸í”„ë¼ ì—…ê·¸ë ˆì´ë“œ**: Pro í”Œëœ + ë©”ëª¨ë¦¬ ì¦ì„¤

### ë‚®ìŒ (3-6ê°œì›”)
7. **Edge Computing**: ê¸€ë¡œë²Œ ì„±ëŠ¥ ìµœì í™”
8. **ë°ì´í„° íŒŒí‹°ì…”ë‹**: ì§€ì—­ë³„ ë¶„ì‚°
9. **ê³ ê¸‰ ëª¨ë‹ˆí„°ë§**: ML ê¸°ë°˜ ì„±ëŠ¥ ì˜ˆì¸¡

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ê²€ì¦

### ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¶”ì 
```python
# í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ ëª¨ë‹ˆí„°ë§
PERFORMANCE_TARGETS = {
    "api_response_time_ms": 50,      # ëª©í‘œ: 50ms
    "api_error_rate_percent": 0.1,   # ëª©í‘œ: 0.1%
    "metadata_response_time_ms": 3000  # ì„ê³„ê°’: 3ì´ˆ
}

async def validate_performance_targets():
    """ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„± ì—¬ë¶€ ê²€ì¦"""
    metrics = await get_current_metrics()

    results = {}
    for metric, target in PERFORMANCE_TARGETS.items():
        current_value = metrics.get(metric)
        results[metric] = {
            "current": current_value,
            "target": target,
            "status": "pass" if current_value <= target else "fail"
        }

    return results
```

### ìë™ ì•Œë¦¼ ì‹œìŠ¤í…œ
```python
async def setup_performance_alerts():
    """ì„±ëŠ¥ ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ìë™ ì•Œë¦¼"""
    if await check_api_response_time() > 100:  # 100ms ì´ˆê³¼
        await send_alert("API ì‘ë‹µ ì‹œê°„ ì„ê³„ê°’ ì´ˆê³¼")

    if await check_error_rate() > 0.2:  # 0.2% ì´ˆê³¼
        await send_alert("API ì—ëŸ¬ìœ¨ ì„ê³„ê°’ ì´ˆê³¼")
```

---

*Updated: 2024ë…„ 9ì›” 15ì¼ - í•œêµ­ ì„±ëŠ¥ì§€í‘œ ëŒ€ì‘ ìµœì í™” ê°€ì´ë“œ*